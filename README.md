# academ.ai
  Academ is an LLM application used for tutoring users. This application extracts questions from an uploaded pdf file from the user, then allows the user to select which problem(s) they wish to get tutoring help from the LLM as needed.

## How academ.ai Works:
  The user can select the virtual envrionment with all the packages found in the packages.txt file, then activate thier environment and run "node server.js" doing so will run the application locally on the chosen port (default port is 3000) as found in teh server.js file. The user can then type "localhost:3000" into thier browser to run the application. When uploading a file, the file must be formatted as a pdf file. Once the file is loaded and questions are extracted, the user can select which question(s) they wish to get help from. The LLM will respond once the question is selected, and the user is then free to message the LLM.

## Backend Python Files:
  * load_questions.py uses the ollama module to generate responses from the llama3:instruct model and the langchain package to load the pdf files. After the pdf file is uploaded byu the user, we make a system message to llama3 to extract each question in json format. Then using the file path provided by the user, it loads the pdf file into one large chunk of text and then turns that large chunk of text into a user message. The system and user messages are added to the chat history, then a response with the json formatted questions is generated using the chat history and is sent back to the front end.
  * questions_selection.py takes the selected question from the front end, then creates a system message for llama3 telling it to act as a tutor for the user. The chat history is updated and used to generate a response to the selected question, then the chat history is updated again with the LLM response, and the LLM response and chat history are sent to the server.
  * app.py recieves the chat history and user message from the front end, updates the chat history with the user message, and uses the chat history to generate a response from llama3. It then adds the response to the chat history, and sends the response and chat history to the server.